{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping and summarising operations in aggregation pipelines\n",
    "\n",
    "In the previous notebook, you were introduced to the simple aggregation pipelines, focussing on how pipeline stages could be created to filter records through selection, projection and limit operators, as well as \"unwinding\" lists into separate documents, one per array (list) element.\n",
    "\n",
    "In this notebook, you will see how we can perform grouping and summarising operations within a pipeline.\n",
    "\n",
    "This can be particularly useful because it keeps the summarising operations close to the data. Rather than have to return a large number of records and hold them in memory as a *pandas* dataframe, and then create a summary table from  the dataframe, we can just retrieve summary table directly from the pipeline.\n",
    "\n",
    "Let's start in the normal way by loading in some required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a connection to the MongoDB server, then open the accidents database and set up references to the `accidents` and `labels` collections:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the document database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebooks for parts 14, 15 and 16, you will be using a document database to manage data. As with the relational database you looked at in previous sections, the data in the database is *persistent*. The document database, MongoDB, is described as \"NoSQL\" to reflect that it does not use the tabular format of the relational database to store data. However, many of properties of a formal RDBMS apply to MongoDB, including the need to connect to the database server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with PostgreSQL, the MongoDB database server runs independently from the Jupyter notebook server. To interact with it, you need to set up an explicit connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting your database credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with a database, we need to create a *connection* to the database. A connection allows us to manipulate the database, and query its contents (depending on what usage rights you have been granted). For the SQL notebooks in TM351, the details of your connection will depend upon whether you are using the OU-hosted server, accessed via [tm351.open.ac.uk](https:tm351.open.ac.uk), or whether you are using a version hosted on your own computer, which you should have set up using either Vagrant or Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up the connection, you need a login name and a pasword. we will use the variables `DB_USER` and `DB_PWD` to hold the user name and password respectively that you will use to connect to the database. Run the appropriate cell to set your credentials in the following cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the database on [tm351.open.ac.uk](https:tm351.open.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using the Open University hosted server, you should execute the following cell, using your OUCU as the value of `DB_USER`, and the password you were given at the beginning of the module. Note that if the cell is in RAW NBconvert style, you will need to change its type to Code in order to execute it.\n",
    "\n",
    "The variables `DB_USER` and `DB_PWD` are strings, and so you need to put them in quotes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If you are using the remote environment, change this cell\n",
    "# type to \"code\", and execute it\n",
    "\n",
    "DB_USER='xxx99'            # Enter your OUCU here (in quotes)\n",
    "DB_PWD='your_password'     # Enter your password here (in quotes)\n",
    "\n",
    "import urllib\n",
    "\n",
    "MONGO_CONNECTION_STRING = f\"mongodb://{DB_USER}:{urllib.parse.quote_plus(DB_PWD)}@localhost:27017/?authsource=user-data\"\n",
    "print(f\"MONGO_CONNECTION_STRING = {MONGO_CONNECTION_STRING}\")\n",
    "\n",
    "DB_NAME=DB_USER\n",
    "print(f\"DB_NAME = {DB_NAME}\")\n",
    "\n",
    "ACCIDENTS_DB_NAME=\"accidents-2012\"\n",
    "# ACCIDENTS_DB_NAME=\"accidents-09-12\" # Uncomment this line to use the full accident database\n",
    "\n",
    "print(f\"ACCIDENTS_DB_NAME = {ACCIDENTS_DB_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, note that the connection string contains an additional option at the end: `?authsource=user-data`. For the MongoDB setup that we are using here, this option tells Mongo where to look for the authentication database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the database on a locally hosted machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running the Jupyter server on your own machine, via Docker or Vagrant, you should execute the following cell. Note that if the cell is in RAW NBconvert style, you will need to change its type to Code in order to execute it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If you are using a locally hosted environment, change this cell\n",
    "# type to \"code\", and execute it\n",
    "\n",
    "MONGO_CONNECTION_STRING = f\"mongodb://localhost:27017/\"\n",
    "print(f\"MONGO_CONNECTION_STRING = {MONGO_CONNECTION_STRING}\")\n",
    "\n",
    "DB_NAME=\"test_db\"  # For a local VCE, this can be any value\n",
    "print(f\"DB_NAME = {DB_NAME}\")\n",
    "\n",
    "ACCIDENTS_DB_NAME=\"accidents\"\n",
    "print(f\"ACCIDENTS_DB_NAME = {ACCIDENTS_DB_NAME}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the locally hosted versions of the environment give you full administrator rights, which is why you do not need to specify a user name or password. Obviously, this would not generally not be granted on a multi-user database, unless you are the database administrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now set up a connection to the database. As with PostgreSQL, we use a connection string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MONGO_CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The connection string is made up of several parts:\n",
    "\n",
    "- `mongodb` : tells `pymongo` that we will use MongoDB as our database engine\n",
    "- Your user name and (character escaped) password, separated by a colon if you are using the remote server. If you are using a local server, you will be logged on as an adminstrator, and do not need to specify a name or password.\n",
    "- `localhost:27017` : the port on which the database engine is listening.\n",
    "- A reference to the authentication file (`?authsource=user-data`), if you are using the remote server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now connect to the database with a `pymongo.MongoClient` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client=MongoClient(MONGO_CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be connected to the MongoDB database server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The accidents database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accidents database takes a long time to set up, so we have already imported it into a MongoDB database so that you can work with it. Note that on the remote VCE, the database is read-only, so you will not be able to alter its contents, although you can copy the contents into your own database space as discussed in the previous MongoDB notebooks, and alter that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells in the earlier section, Setting up the document database, put the name of the accidents database into the variable `ACCIDENTS_DB_NAME`. Use this value to set up the connection to the `accidents` database and collections within it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_db=mongo_client[ACCIDENTS_DB_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the names of the collections in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_db.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will introduce some of the different collections in the rest of the materials, but let's start with the `accidents` collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_collection=accidents_db['accidents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This collection contains information on individual accidents. We can see how many examples it contains with the `.count_documents()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_collection.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also specify the `labels` collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=accidents_db['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be plotting some charts, so increase the default plot size to make things easier to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a larger plot size than the default\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping in aggregation pipelines\n",
    "\n",
    "A `$group` operator can be applied to the records in a pipeline to perform summary aggregation operations over the group.\n",
    "\n",
    "For example, the following  pipeline:\n",
    "\n",
    "- finds all the accidents at 30mph or above;\n",
    "- groups the accidents by speed limit and finds the number of accidents at each speed limit within the group.\n",
    "\n",
    "```python\n",
    "pipeline = [{'$match': {'Speed_limit': {'$gte': 30}}},\n",
    "            {'$group': {'_id': '$Speed_limit',\n",
    "                        'num_accidents': {'$sum': 1}}}]\n",
    "```\n",
    "\n",
    "In this case, the first step of the pipeline retrieves records of accidents that occurred at 30 mile per hour or greater and the second step groups the results as follows:\n",
    "\n",
    "- group the accidents using an `_id` value set as the value being grouped on (which is to say, the value of the speed limit, `{'_id': '$Speed_limit'}`);\n",
    "- having grouped the documents, a so-called \"accumulator expression\" is applied to each document in the group. In this case, we obtain the number of accidents associated with that group (`num_accidents`) and add 1 (one) to it (`{'$sum': 1}`) for each document.\n",
    "\n",
    "Other accumulator operators include `$min` and `$max` (for a full list, see the [MongoDB aggregation pipeline group/accumulator operator docs](https://docs.mongodb.com/manual/reference/operator/aggregation/#accumulators-group)).\n",
    "\n",
    "It may look quirky, but this is the idiom for counting members in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": false
   },
   "outputs": [],
   "source": [
    "# Pull out all the accidents at 30mph or above\n",
    "pipeline = [{'$match': {'Speed_limit': {'$gte': 30}}},\n",
    "            # Group by speed\n",
    "            {'$group': {'_id': '$Speed_limit',\n",
    "                        'num_accidents': {'$sum': 1}}}]\n",
    "\n",
    "# Show totals for each speed.\n",
    "results = list(accidents_collection.aggregate(pipeline))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put the results in a _pandas_ DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).set_index('_id')\n",
    "\n",
    "# Rename the _id index (representing the group key)\n",
    "# to something more meaningful\n",
    "results_df.index.name = 'speed_limit'\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-success"
    ]
   },
   "source": [
    "*For many of the aggregation pipeline activities below, build up the pipeline in stages. The `$limit` operator is your friend here: it will allow you to see what the pipeline produces without being overwhelmed by thousands of items.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 1\n",
    "Find all the accidents at 30mph or above, group them by speed limit and accident severity, and find the number of accidents at each speed limit/severity combination.\n",
    "\n",
    "Hint: If you give multiple keys for a single `$group` operation, it will return one group for each combination of those keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "student": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "To create the pipeline, we need to match speed limits greater than or equal to 30 mph and then group the results by speed and severity. We can then count the number of items in each group by adding 1 for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pull out all the accidents at 30mph or above, group by speed and severity, \n",
    "#   and show totals at each speed/severity combination.\n",
    "_pipeline1 = [{'$match': {'Speed_limit': {'$gte': 30}}},\n",
    "              {'$group': {'_id': {'Speed_limit': '$Speed_limit', \n",
    "                                'Accident_Severity': '$Accident_Severity'},\n",
    "                        'num_accidents': {'$sum': 1}}}]\n",
    "\n",
    "_results1 = list(accidents_collection.aggregate(_pipeline1))\n",
    "\n",
    "display(_results1[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "####  End of Activity 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame from the Multi-Attribute Group\n",
    "\n",
    "Using `json_normalize` to cast the result to a *pandas* dataframe flattens the multiple index terms to columns with `_id.` prefix column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the sample results from the activity answer\n",
    "severity_speed_df = _results1\n",
    "# Alternatively, use your own results\n",
    "\n",
    "severity_speed_df = pd.json_normalize(severity_speed_df)\n",
    "\n",
    "severity_speed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace the column names with something a little tidier by using a `dict` comprehension to create a lookup from `_id.` prefixed columns names to clean column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For column names starting with _id,\n",
    "# create a lookup from that column name to a cleaned column name\n",
    "column_renames = {c:c.replace('_id.', '') for c in severity_speed_df.columns if c.startswith('_id.')}\n",
    "\n",
    "severity_speed_df.rename(columns=column_renames, inplace=True)\n",
    "severity_speed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also relabel the accident severity with meaningful labels in the normal way, taking the opportunity to cast them as ordered categorical items as we do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accident severity labels\n",
    "accident_severity_labels = labels.find_one({'label': 'Accident_Severity'})['codes']\n",
    "\n",
    "\n",
    "# Set accident severity labels as strings\n",
    "severity_speed_df['Accident_Severity'] = severity_speed_df['Accident_Severity'].astype(str).map(accident_severity_labels)\n",
    "\n",
    "# Then ma the accident severity labels to an ordered category type\n",
    "severity_speed_df['Accident_Severity'] = \\\n",
    "    severity_speed_df['Accident_Severity'].astype(CategoricalDtype(['Slight','Serious', 'Fatal'],\n",
    "                                                            ordered=True))\n",
    "\n",
    "severity_speed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Long Format Data With `seaborn.barplot()`\n",
    "\n",
    "With the data in this long form, we can plot it directly using the `seaborn.barplot()` function, using the speed limit as the grouping value on the *x*-axis, the number of acccidents as the bar height on the *y*-axis and the accident severity for the colour (*hue*) grouping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"Speed_limit\", y=\"num_accidents\",\n",
    "                 hue=\"Accident_Severity\", data=severity_speed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 2\n",
    "Using an aggegation pipeline, group the accidents by number of vehicles and number of casualties. From each group, find the number of accidents for each combination of vehicle and casualty number.\n",
    "\n",
    "Visualise the data using a *seaborn* scatterplot chart, `sns.scatterplot()`. Use the number of vehicles for the *x*-axis, the number of casualties on the *y*-axis, and the number of accidents for the *size*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "student": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here.\n",
    "\n",
    "# You may find it convenient to construct your solution over several code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Run the pipeline to generate the data and unroll the cursor response into a list of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_pipeline2 = [{'$group': {'_id': {'Number_of_Casualties': '$Number_of_Casualties', \n",
    "                                  'Number_of_Vehicles': '$Number_of_Vehicles'},\n",
    "                          'num_accidents': {'$sum': 1}}}]\n",
    "\n",
    "_results2 = list(accidents_collection.aggregate(_pipeline2))\n",
    "_results2[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Create a dataframe from the results using whatever method you prefer. Here, I use the `json_normalise` route and then rename the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_results2_long_df = pd.json_normalize(_results2)\n",
    "_results2_long_df.columns = [c.replace('_id.', '') for c in _results2_long_df.columns]\n",
    "_results2_long_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Visualise the data using *seaborn*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "ax = sns.scatterplot(x=\"Number_of_Vehicles\", y=\"Number_of_Casualties\",\n",
    "                size=_results2_long_df[\"num_accidents\"].to_list(),\n",
    "                data=_results2_long_df)\n",
    "\n",
    "\n",
    "# Only use integer tick labels\n",
    "ax.axes.get_xaxis().set_major_locator(MaxNLocator(integer=True)) \n",
    "ax.axes.get_yaxis().set_major_locator(MaxNLocator(integer=True)) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "(Note that we have converted the `size` argument to a list because of a known bug in [matplotlib and seaborn](https://stackoverflow.com/questions/63443583/seaborn-valueerror-zero-size-array-to-reduction-operation-minimum-which-has-no)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "####  End of Activity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 3 (optional)\n",
    "\n",
    "Using an aggregation pipeline, group accidents by severity and junction type (`Junction_Detail`) and find the number of accidents for each combination of junction and severity.\n",
    "\n",
    "Cast any `NaN` results to 0.\n",
    "\n",
    "Store the results in a long DataFrame, casting any `NaN` results to 0 and using meaningful severity and junction detail text labels (e.g. Fatal, Serious; Roundabout, Crossroads) in place of numerical code values.\n",
    "\n",
    "Visualise the resulting dataframe as an appropriately ordered grouped bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "student": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here.\n",
    "\n",
    "# You may find it convenient to construct your solution over several code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Start by retrieving the data into a list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_pipeline4 = [{'$match': {'Speed_limit': {'$gte': 30}}},\n",
    "              {'$group': {'_id': {'Junction_Detail': '$Junction_Detail', \n",
    "                                  'Accident_Severity': '$Accident_Severity'},\n",
    "                          'num_accidents': {'$sum': 1}}}]\n",
    "\n",
    "_results4 = list(accidents_collection.aggregate(_pipeline4))\n",
    "_results4[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Convert the list to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_results4_long_df = pd.json_normalize(_results4)\n",
    "_results4_long_df.columns = [c.replace('_id.', '') for c in _results4_long_df.columns]\n",
    "_results4_long_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Map the numerical codes to human readable labels, as appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "junction_detail_labels = labels.find_one({'label': 'Junction_Detail'})['codes']\n",
    "\n",
    "_results4_long_df['Accident_Severity'] = \\\n",
    "    _results4_long_df['Accident_Severity'].astype(str).map(accident_severity_labels)\n",
    "\n",
    "# Use the categorical datatype\n",
    "_results4_long_df['Accident_Severity'] = \\\n",
    "    _results4_long_df['Accident_Severity'].astype(CategoricalDtype(['Slight','Serious', 'Fatal'],\n",
    "                                                            ordered=True))\n",
    "\n",
    "_results4_long_df['Junction_Detail'] = \\\n",
    "    _results4_long_df['Junction_Detail'].astype(str).map(junction_detail_labels)\n",
    "\n",
    "_results4_long_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Visualise the result, using the `hue_order` to appropriately order the accident severities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"num_accidents\", y=\"Junction_Detail\",\n",
    "                 hue=\"Accident_Severity\",\n",
    "                 hue_order=['Slight', 'Serious', 'Fatal'],\n",
    "                 data=_results4_long_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "####  End of Activity 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-warning"
    ]
   },
   "source": [
    "## Optional *pandas* data wrangling practice examples\n",
    "\n",
    "*Optional activities to provide practice on using pandas datashaping `.pivot()` operations with pipeline results data. The example solutions may also be useful as worked examples, so just remember they're available here in case you want to check back on them in future!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 4 (optional)\n",
    "\n",
    "Reshaping and plotting the `severity_speed_df` data using a *pandas* `.pivot()`.\n",
    "\n",
    "*Click the arrow in the margin or run this cell to reveal this optional practice activity.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "Convert the long format `severity_speed_df` dataframe containing number of accidents for each combination of speed limit and severity, into a wide format dataframe with columns corresponding to accident severity and an index, in decreasing order, of speed limits.\n",
    "\n",
    "Visualise the result as a bar chart.\n",
    "\n",
    "*Hint: use a pandas `pivot` to reshape the data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "student": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here.\n",
    "\n",
    "# You may find it convenient to construct your solution over several code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Pivot the long form dataframe into a wide form using accident severities as the column values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_results3_wide_df = severity_speed_df.pivot(index='Speed_limit',\n",
    "                                            columns='Accident_Severity',\n",
    "                                            values='num_accidents')\n",
    "_results3_wide_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Sort the index of the dataframe in descending speed order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_results3_wide_df.sort_index(ascending=False, inplace=True)\n",
    "_results3_wide_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "We can visualise the wide format dataframe directly using a *pandas* `bar` chart plotting method. The function groups items by row, assigning each column to its own color-designated bar, with groups indexed by the row index value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = _results3_wide_df.plot(kind='bar')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "####  End of Activity 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "heading_collapsed": true
   },
   "source": [
    "### Activity 5 (optional)\n",
    "\n",
    "More reshaping and plotting the `severity_speed_df` data using a *pandas* `.pivot()`.\n",
    "\n",
    "*Click the arrow in the margin or run this cell to reveal this optional practice activity.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Using your dataframe from Activity 2, where you grouped the accidents by number of vehicles and number of casualties, reshape the dataframe to a wide format using the number of vehicles for the columns and number of casualties as the index. \n",
    "\n",
    "Replace any `NaN` fields with 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "student": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here.\n",
    "\n",
    "# You may find it convenient to construct your solution over several code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Reshape the table from long to wide form using a pivot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_results4_wide_df = _results2_long_df.pivot(index='Number_of_Casualties',\n",
    "                                              columns='Number_of_Vehicles',\n",
    "                                              values='num_accidents')\n",
    "_results4_wide_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Replace the `NA` values with `0` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_results4_wide_df.fillna(0, inplace=True)\n",
    "_results4_wide_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "####  End of Activity 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projections  on pipeline `$group` results\n",
    "\n",
    "As well as limiting the return of particular fields in a document, the `$project` operator also allows us to project elements returned from the `$group` phase in two additional ways:\n",
    "\n",
    "- firstly, onto newly named variables\n",
    "- secondly, onto calculated values derived from the group members.\n",
    "\n",
    "Let's start by defining a grouping operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = {'$group': {'_id': {'Speed_limit': '$Speed_limit'}}}\n",
    "\n",
    "pipeline = [group]\n",
    "\n",
    "list(accidents_collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming group `_id` fields\n",
    "\n",
    "We might then project the `_id.Speed_limit` value returned from a grouping operation onto the simpler `Speed_limit` value, which makes for a cleaner output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = {'$project': {'Speed_limit': '$_id.Speed_limit'}}\n",
    "\n",
    "pipeline = [group, project]\n",
    "\n",
    "list(accidents_collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an expanded view, the pipeline looks like this:\n",
    "\n",
    "```python\n",
    "pipeline = [{'$group': {'_id': {'Speed_limit': '$Speed_limit'}}}, \n",
    "            {'$project': {'Speed_limit': '$_id.Speed_limit'}}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also suppress the display of the `_id` document by setting it's return value to the \"false\" `0` value in the projection step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [group,\n",
    "            {'$project': {'Speed_limit': '$_id.Speed_limit',\n",
    "                          '_id':0}}]\n",
    "\n",
    "list(accidents_collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Items In the Pipeline\n",
    "We can sort the output by adding a sort step to the pipeline, passing as true (`1`) the field(s) we want to sort on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = {'$sort':{'Speed_limit': 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this as part of a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "pipeline = [group, project, sort]\n",
    "\n",
    "# Run the pipeline\n",
    "list(accidents_collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can use multiple projections within the same pipeline. For example, if we know all we are interested in is the `Speed_limit` field, we can start the pipeline with a projection onto just that element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [{'$project': {'Speed_limit':1}},\n",
    "            {'$group': {'_id': {'Speed_limit': '$Speed_limit'}}},\n",
    "            {'$project': {'Speed_limit': '$_id.Speed_limit',\n",
    "                          '_id':0}}]\n",
    "list(accidents_collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Calculations as Part of the Projection\n",
    "\n",
    "As well as filtering and renaming elements, the `$project` operator also provides a means by which we can perform calculations over document values using a range of aggregation operators, including arithmetic expression operators, conditional and comparison operators and date, text and string operators.\n",
    "\n",
    "For example, aggregation operators, which take the form `{<operator>: [ <argument1>, <argument2> ... ]}` or `{ <operator>: <argument1>}`, include, but are not limited to:\n",
    "\n",
    "- `$add`, `$subtract`, `$multiply`, `$divide`\n",
    "- `$eq`, `$gt`, `$gte`, `$lt`, `$lte`, `$ne`\n",
    "- `$dateFromString`, `$dayOfMonth`, `$dayOfWeek`, `$dayOfYear`\n",
    "- `$sin`, `$cos`, `$tan`, `$asin` etc.\n",
    "- `$toInt`, `$toString` etc\n",
    "\n",
    "\n",
    "*For a full list, see the [MongoDB aggegation pipeline operator docs](https://docs.mongodb.com/manual/reference/operator/aggregation/).*\n",
    "\n",
    "For example, we could find the speed limit in km per hour rather than miles per hour by multiplying the speed limit in mph by 1.61.\n",
    "\n",
    "*Note that the renamed `$Speed_limit` document is not available within the `$project` scope.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [group,\n",
    "            {'$project': {'Speed_limit': '$_id.Speed_limit',\n",
    "                         '_id':0,\n",
    "                          'Speed_limit_kph': {'$multiply': ['$_id.Speed_limit', 1.61]}}},\n",
    "            sort]\n",
    "\n",
    "list(accidents_collection.aggregate(pipeline))[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in an expanded form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [{'$group': {'_id': {'Speed_limit': '$Speed_limit'}}},\n",
    "            {'$project': {'Speed_limit': '$_id.Speed_limit',\n",
    "                         '_id': 0,\n",
    "                          'Speed_limit_kph': {'$multiply': ['$_id.Speed_limit', 1.61]}}},\n",
    "            {'$sort':{'Speed_limit': 1}}]\n",
    "\n",
    "list(accidents_collection.aggregate(pipeline))[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 6\n",
    "Use an aggegation pipeline to find the \"average\" number of vehicles and casualties per accident at each speed limit. Replace the `_id` of each speed limit group with the plain `Speed_limit`.\n",
    "\n",
    "Store the results in a DataFrame with the averages as the columns and speed limits as the index, sorted by increasing speed limit.\n",
    "\n",
    "Visualise the data using an appropriately defined bar chart.\n",
    "\n",
    "Hint: Use `$group` operator with the `$sum` accumulator expression to find the total vehicles and casualties, then use `$project` to find the averages and rename the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "student": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here.\n",
    "\n",
    "# You may find it convenient to construct your solution over several code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Create a group for each speed limit, then `project` over the `$Number_of_Casualties` and `$Number_of_Vehicles` to find the total number of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_group = {'$group': {'_id': {'Speed_limit': '$Speed_limit'},\n",
    "                     'total_casualties': {'$sum': '$Number_of_Casualties'},\n",
    "                     'total_vehicles': {'$sum': '$Number_of_Vehicles'},\n",
    "                     'num_accidents': {'$sum': 1}}}\n",
    "\n",
    "_pipeline5a = [_group]\n",
    "\n",
    "list(accidents_collection.aggregate(_pipeline5a))[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Find the average number of casualties per accident by dividing the total number of casualties by the total number of accidents, and likewise for the average number of vehicles per accident.\n",
    "\n",
    "Also use the projection to rename the `$_id.Speed_limit` document and remove the `$_id` records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_project = {'$project': {'average_casualties': {'$divide': ['$total_casualties', '$num_accidents']},\n",
    "                         'average_vehicles': {'$divide': ['$total_vehicles', '$num_accidents']},\n",
    "                         'Speed_limit': '$_id.Speed_limit',\n",
    "                         '_id': 0}}\n",
    "\n",
    "_pipeline5b = [_group, _project]\n",
    "\n",
    "list(accidents_collection.aggregate(_pipeline5b))[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "A final element of the pipeline sorts the resulting documents by `$Speed_limit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_sort = {'$sort': {'Speed_limit': 1}}\n",
    "\n",
    "_pipeline5c = [_group, _project, _sort]\n",
    "\n",
    "_results5 = list(accidents_collection.aggregate(_pipeline5c))\n",
    "_results5[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Put the results in a DataFrame. The speed limit index value will allow us to group bars by this dimension in our bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_results5_df = pd.json_normalize(_results5)\n",
    "\n",
    "# Set the index\n",
    "_results5_df.set_index('Speed_limit', inplace=True)\n",
    "_results5_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Finally, use a simple *pandas* plot to visualise the results using a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = _results5_df.plot(kind='bar')\n",
    "\n",
    "# Put the legend outside the chart so it doesn't occlude the bars\n",
    "ax.legend(bbox_to_anchor=(1, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "####  End of Activity 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 7 (optional)\n",
    "\n",
    "Use an aggegation pipleine to find number of casualties for each combination of casualty severity and casualty age band. \n",
    "\n",
    "Store the results in a DataFrame with the severities as the columns and age bands as the index. The columns and index should contain the text labels (e.g. 21-25, 46-55; Fatal, Slight), not the codes.\n",
    "\n",
    "Hint: Use `$unwind` to examine each `casualty` sub-document in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "student": true
   },
   "outputs": [],
   "source": [
    "# Insert your solution here.\n",
    "\n",
    "# You may find it convenient to construct your solution over several code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Start of by defining a pipeline that unwinds the `$Casualties` lists and then group the result by casualty age band (`Age_Band_of_Casualty`) and severity (`Casualty_Severity`), using the `$sum` accumulator expression to count the number of records in each group.\n",
    "\n",
    "Sort the results by the casualty age band for sensible charting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_pipeline6 = [{'$unwind': '$Casualties'},\n",
    "              {'$group': {'_id': {'Age_Band_of_Casualty': '$Casualties.Age_Band_of_Casualty',\n",
    "                                  'Casualty_Severity': '$Casualties.Casualty_Severity'},\n",
    "                          'num_accidents': {'$sum': 1}}},\n",
    "              {'$sort': {'_id.Age_Band_of_Casualty': 1}}]\n",
    "\n",
    "_results6 = list(accidents_collection.aggregate(_pipeline6))\n",
    "_results6[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Make sure we have the human readable labels to hand.\n",
    "\n",
    "We might also consider creating an ordered categorial type for the age bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "casualty_severity_labels = labels.find_one({'label': 'Casualty_Severity'})['codes']\n",
    "\n",
    "age_band_casualty_labels = labels.find_one({'label': 'Age_Band_of_Casualty'})['codes']\n",
    "\n",
    "# Created ordered category type for acge bands\n",
    "ordered_age_bands = [age_band_casualty_labels[k] for k in sorted(age_band_casualty_labels.keys(), key=int)]\n",
    "age_band_category = CategoricalDtype(ordered_age_bands, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Put the result into a dataframe, rename the columns, and map the codes to human readable labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_results6_long_df = pd.json_normalize(_results6)\n",
    "\n",
    "#Rename the columns\n",
    "_results6_long_df.columns = _results6_long_df.columns = [c.replace('_id.', '') for c in _results6_long_df.columns]\n",
    "\n",
    "\n",
    "#Map the codes to human readable labels and thence to ordered categorical labels\n",
    "_results6_long_df['Age_Band_of_Casualty'] = \\\n",
    "    _results6_long_df['Age_Band_of_Casualty'].astype(str).map(age_band_casualty_labels).astype(age_band_category)\n",
    "\n",
    "_results6_long_df['Casualty_Severity'] = \\\n",
    "    _results6_long_df['Casualty_Severity'].astype(str).map(casualty_severity_labels)\n",
    "\n",
    "_results6_long_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "Finally, create a bar chart of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"num_accidents\", y=\"Age_Band_of_Casualty\",\n",
    "                 hue=\"Casualty_Severity\",\n",
    "                 data=_results6_long_df)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "####  End of Activity 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning Data\n",
    "\n",
    "In the `accidents` data, the age band of driver and casualty fields represent \"binned\" ranges. The `Number_of_Vehicles` and `Number_of_Casualties` fields give actual counts, but as we have seen, in some situations it may also be useful to bin these into different groups.\n",
    "\n",
    "For example, we might categorise accidents based on the number of vehicles involved in the accident, defining the categories: single vehicle crashes, two car accidents, multiple vehicle incidents (up to and including five vehicles, for example) and \"huge pile ups\" of six vehicles or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-warning"
    ]
   },
   "source": [
    "*In a formal report, you should probably be more circumspect in the naming of the different categories!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can allocate documents to different bins using the aggregation pipeline `$bucket` operator.\n",
    "\n",
    "This requires items to be grouped in a particular way, and then allocated to different bounded groups based on a itemised boundary list. The list is parsed to create pairwise bounded ranges where the lower bound values are inclusive and the upper bound values are exclusive:\n",
    "\n",
    "For example, the boundary list `[0, 1, 2, 3, 6, 999]` identifies bins:\n",
    "\n",
    "- `[1, 2)`: 1 vehicle (1 inclusive to 2 exclusive)\n",
    "- `[2, 3)`: 2 vehicles (2 inclusive to 3 exclusive)\n",
    "- `[3, 6)`: 3-5 vehicles (3 inclusive to 6 exclusive)\n",
    "- `[6, 999)`: 6 vehicles and up (6 inclusive to 999 exclusive, which we set to greater than the maximum number of vehicles, guessing at an upper bound here, although we could set one explicitly based on the actual maximum vehicle count.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = {'$bucket':\n",
    "          {'groupBy': \"$Number_of_Vehicles\",\n",
    "           'boundaries': [0, 1, 2, 3, 6, 999],\n",
    "           'output':\n",
    "               { \"count\": { '$sum': 1 } }\n",
    "          }\n",
    "         }\n",
    "\n",
    "list(accidents_collection.aggregate([bucket]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check these with some counts over equivalent queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_vehicle_accidents = accidents_collection.count_documents({\"Number_of_Vehicles\":1})\n",
    "two_vehicle_accidents = accidents_collection.count_documents({\"Number_of_Vehicles\":2})\n",
    "six_and_up_vehicle_accidents = accidents_collection.count_documents({\"Number_of_Vehicles\": {\"$gte\":6}})\n",
    "\n",
    "print(f'''There were {single_vehicle_accidents} single vehicle accidents, \\\n",
    "{two_vehicle_accidents} two vehicle accidents and \\\n",
    "{six_and_up_vehicle_accidents} accidents involving six or more vehicles.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "student": true
   },
   "source": [
    "*Do the numbers match?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "If you are working through this Notebook as part of an inline exercise, return to the module materials now.\n",
    "\n",
    "If you are working through this set of Notebooks as a whole, move on to `15.5 Introducing the Roads collection`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
