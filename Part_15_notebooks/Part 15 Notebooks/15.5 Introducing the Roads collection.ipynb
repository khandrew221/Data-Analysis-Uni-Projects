{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the `roads` collection\n",
    "\n",
    "Thus far, you have explored the `accidents` collection and of road traffic accident data, and cross-referenced items with in to the `labels` metadata collection, which provides human readable labels for `accidents` data numerical codes. This notebook introduces a new dataset, the `roads` collection.\n",
    "\n",
    "The `roads` collection contains road related meta-data and daily road traffic flow for a wide range of roads in the UK road network. The values represent *the number of vehicles that travel past (in both directions) the location on an average day of the year* and are recorded *for every junction-to-junction link on the motorway and 'A' road network, and for some minor roads in Great Britain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-success"
    ]
   },
   "source": [
    "*The data was originally published by the Department for Transport (DfT) under an Open Government License and then loaded by the TM351 module team into MongoDB. For more details, see [roadtraffic.dft.gov.uk](https://roadtraffic.dft.gov.uk/).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are encouraged to explore the dataset by writing your own queries if there are particular questions about the traffic flows that you are curious about.\n",
    "\n",
    "As ever, let's load in some required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "\n",
    "# Seaborn for charts...\n",
    "import seaborn as sns\n",
    "\n",
    "# folium for maps...\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the document database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebooks for parts 14, 15 and 16, you will be using a document database to manage data. As with the relational database you looked at in previous sections, the data in the database is *persistent*. The document database, MongoDB, is described as \"NoSQL\" to reflect that it does not use the tabular format of the relational database to store data. However, many of properties of a formal RDBMS apply to MongoDB, including the need to connect to the database server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with PostgreSQL, the MongoDB database server runs independently from the Jupyter notebook server. To interact with it, you need to set up an explicit connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting your database credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with a database, we need to create a *connection* to the database. A connection allows us to manipulate the database, and query its contents (depending on what usage rights you have been granted). For the SQL notebooks in TM351, the details of your connection will depend upon whether you are using the OU-hosted server, accessed via [tm351.open.ac.uk](https:tm351.open.ac.uk), or whether you are using a version hosted on your own computer, which you should have set up using either Vagrant or Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up the connection, you need a login name and a pasword. we will use the variables `DB_USER` and `DB_PWD` to hold the user name and password respectively that you will use to connect to the database. Run the appropriate cell to set your credentials in the following cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the database on [tm351.open.ac.uk](https:tm351.open.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using the Open University hosted server, you should execute the following cell, using your OUCU as the value of `DB_USER`, and the password you were given at the beginning of the module. Note that if the cell is in RAW NBconvert style, you will need to change its type to Code in order to execute it.\n",
    "\n",
    "The variables `DB_USER` and `DB_PWD` are strings, and so you need to put them in quotes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If you are using the remote environment, change this cell\n",
    "# type to \"code\", and execute it\n",
    "\n",
    "DB_USER='xxx99'            # Enter your OUCU here (in quotes)\n",
    "DB_PWD='your_password'     # Enter your password here (in quotes)\n",
    "\n",
    "import urllib\n",
    "\n",
    "MONGO_CONNECTION_STRING = f\"mongodb://{DB_USER}:{urllib.parse.quote_plus(DB_PWD)}@localhost:27017/?authsource=user-data\"\n",
    "print(f\"MONGO_CONNECTION_STRING = {MONGO_CONNECTION_STRING}\")\n",
    "\n",
    "DB_NAME=DB_USER\n",
    "print(f\"DB_NAME = {DB_NAME}\")\n",
    "\n",
    "ACCIDENTS_DB_NAME=\"accidents-2012\"\n",
    "# ACCIDENTS_DB_NAME=\"accidents-09-12\" # Uncomment this line to use the full accident database\n",
    "\n",
    "print(f\"ACCIDENTS_DB_NAME = {ACCIDENTS_DB_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, note that the connection string contains an additional option at the end: `?authsource=user-data`. For the MongoDB setup that we are using here, this option tells Mongo where to look for the authentication database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the database on a locally hosted machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running the Jupyter server on your own machine, via Docker or Vagrant, you should execute the following cell. Note that if the cell is in RAW NBconvert style, you will need to change its type to Code in order to execute it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If you are using a locally hosted environment, change this cell\n",
    "# type to \"code\", and execute it\n",
    "\n",
    "MONGO_CONNECTION_STRING = f\"mongodb://localhost:27017/\"\n",
    "print(f\"MONGO_CONNECTION_STRING = {MONGO_CONNECTION_STRING}\")\n",
    "\n",
    "DB_NAME=\"test_db\"  # For a local VCE, this can be any value\n",
    "print(f\"DB_NAME = {DB_NAME}\")\n",
    "\n",
    "ACCIDENTS_DB_NAME=\"accidents\"\n",
    "print(f\"ACCIDENTS_DB_NAME = {ACCIDENTS_DB_NAME}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the locally hosted versions of the environment give you full administrator rights, which is why you do not need to specify a user name or password. Obviously, this would not generally not be granted on a multi-user database, unless you are the database administrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now set up a connection to the database. As with PostgreSQL, we use a connection string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MONGO_CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The connection string is made up of several parts:\n",
    "\n",
    "- `mongodb` : tells `pymongo` that we will use MongoDB as our database engine\n",
    "- Your user name and (character escaped) password, separated by a colon if you are using the remote server. If you are using a local server, you will be logged on as an adminstrator, and do not need to specify a name or password.\n",
    "- `localhost:27017` : the port on which the database engine is listening.\n",
    "- A reference to the authentication file (`?authsource=user-data`), if you are using the remote server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now connect to the database with a `pymongo.MongoClient` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client=MongoClient(MONGO_CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be connected to the MongoDB database server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The accidents database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accidents database takes a long time to set up, so we have already imported it into a MongoDB database so that you can work with it. Note that on the remote VCE, the database is read-only, so you will not be able to alter its contents, although you can copy the contents into your own database space as discussed in the previous MongoDB notebooks, and alter that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells in the earlier section, Setting up the document database, put the name of the accidents database into the variable `ACCIDENTS_DB_NAME`. Use this value to set up the connection to the `accidents` database and collections within it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_db=mongo_client[ACCIDENTS_DB_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the names of the collections in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_db.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will introduce some of the different collections in the rest of the materials, but let's start with the `accidents` collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_collection=accidents_db['accidents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This collection contains information on individual accidents. We can see how many examples it contains with the `.count_documents()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_collection.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also specify the `labels` collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=accidents_db['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be plotting some charts, so increase the default plot size to make things easier to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a larger plot size than the default\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the structure of a `roads` collection document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have seen the `accident` and `label` collections in the accident database. In this notebook, we will look at the `roads` collection. Let's set up the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_collection=accidents_db['roads']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what sort of data might be contained in the `roads` collection, let's the most basic question of all — *what's in a single 'road' document?* — from a document picked at random and which we might assume to be representative of documents across the collection as a whole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roads_collection.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a flattened dataframe, the document looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize( [roads_collection.find_one()] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The record describes a road link — a stretch of road between two junctions — with average daily flows for different vehicle types that passed along that link during a particular sample period.\n",
    "\n",
    "Road links have two ends (`A-Junction` and `B-Junction`) which are either junctions or region boundaries, and are located in a particular local authority area (`ONS LA Name`).\n",
    "\n",
    "The `Fd...` keys are the number of vehicles of a particular class of vehicle that passed this point during a particular sample period (in the forward direction, but there's no 'reverse' direction specified).\n",
    "\n",
    "The `LenNet` measure gives the distance (in km) of the road link; `RCat` describes the road category using one of a set of rad category codes, and the `Road` field gives the road number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the codes mean? The decoded human readable label references already form part of the `labels` collection, so we can cross-reference those just as we looked up `accidents` code labels previously.\n",
    "\n",
    "Specifically, we can create a lookup for human readable labels associated with the `RCat` (road category) codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_category_labels = labels.find_one({'label': 'RCat'})['codes']\n",
    "road_category_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `roads` collection also includes some keys that are described using expanded human readable labels, such as labels for decoding the field names for elements starting `Fd`, such as `FdLGV` and `FdHGVA6a`.\n",
    "\n",
    "One way to access these is to create a lookup dictionary of expanded codes created from a dataframe generated from a query on the `labels` collection documents containing `expanded` label elements.\n",
    "\n",
    "For example, create the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labels = pd.json_normalize(labels.find({'expanded': {\"$exists\": True}},\n",
    "                                                  {'label':1, 'expanded':1, '_id':0}))\n",
    "expanded_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a lookup dictionary, keyed by the `label` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_name = expanded_labels.set_index('label').to_dict()['expanded']\n",
    "expanded_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then expand a human readable form of a key code directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_name['FdAll_MV'], expanded_name['FdHGVA6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will map encoded column names onto human readable labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readable_column_names(columns):\n",
    "    \"\"\"Map column codes onto human readable labels.\"\"\"\n",
    "    column_names = []\n",
    "    for k in columns:\n",
    "        label = expanded_name[k] if k in expanded_name else k\n",
    "        column_names.append(label)\n",
    "    # As a one-line using a list comprehension\n",
    "    #column_names = [expanded_name[k] if k in expanded_name else k for k in df.columns]\n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then annotate a dataframe created from documents pulled from the `roads` collection as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(list(roads_collection.find(limit=4)))\n",
    "df.columns = readable_column_names(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the `roads` collection data\n",
    "\n",
    "As well as looking at the `roads` data on a map view, we can also analyse the data in various numerical or statistical ways. In this section we'll review some of the ways we might explore any, arbitrary, numerical dataset, although still framing our questions very much in the context of the data we have to hand.\n",
    "\n",
    "For example, we might review the distribution of road segment lengths, the profile of roads within a particular district or area, or the distributions of traffic flows across different parts of the road network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by having a look at some of the numbers associated with the traffic flow data contained in the `roads` collection. We'll start by analysing the data as represented in a *pandas* dataframe.\n",
    "\n",
    "To obtain the data we need in order to create the dataframe, we'll use the aggregation pipeline technique you met in a previous notebook.\n",
    "\n",
    "We'll begin by considering how many examples there are of each type of road link, and what the average length of each of them is.\n",
    "\n",
    "The `RCat` field gives the road category, which we'll count instances of. The `LenNet` field gives the length of the road link, from which we can find the average length.\n",
    "\n",
    "In the grouping step, we can make use of the `$avg` averaging accumulator operator to find the group averages.\n",
    "\n",
    "As well as the grouping operator, we'll tidy up the attribute names returned from the pipeline using an ultimate `$project` step.\n",
    "\n",
    "We can run the basic pipeline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [{'$group': {'_id': '$RCat',\n",
    "                        'length': {'$avg': '$LenNet'},\n",
    "                        'count': {'$sum': 1}}},\n",
    "            {'$project': {'RCat': '$_id',\n",
    "                          '_id': 0, 'length': 1, 'count': '$count'}}]\n",
    "\n",
    "results = list(roads_collection.aggregate(pipeline))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the `$project` statement, we can retain a field in the projection without renaming it by declaring it as `'name': '$name'` or `'name': 1`.\n",
    "\n",
    "We can also cast the result to a *pandas* dataframe and map the codes in the normal way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_lengths = pd.json_normalize(list(roads_collection.aggregate(pipeline)))\n",
    "\n",
    "# Map code values\n",
    "road_lengths['RCat'] = road_lengths['RCat'].map(road_category_labels)\n",
    "\n",
    "# Map column labels\n",
    "road_lengths.columns = readable_column_names(road_lengths.columns)\n",
    "\n",
    "road_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot this data using a simple scatterplot to show the average road segment length for a particular road category against the number of segments of that category.\n",
    "\n",
    "We can also add an annotation label to each point by applying a labeling function applied to each row of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"length\", y=\"count\", data=road_lengths)\n",
    "\n",
    "def add_chart_label(row, ax, x, y, label):\n",
    "    \"\"\"Add a label to a point at a particular location.\"\"\"\n",
    "    ax.text(row[x], row[y], row[label], horizontalalignment='left')\n",
    "\n",
    "road_lengths.apply(add_chart_label, x='length', y='count',\n",
    "                   label='Road category', ax=ax, axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, rural road links are longer than urban road links. There are more \"principal\" than \"trunk\" road links, probably because \"trunk\" roads are designated major routes.\n",
    "\n",
    "But looking at the labels, what might the \"principal motorways\" relate to?\n",
    "\n",
    "The `.distinct(field, query)` Mongo collection method ([docs](https://docs.mongodb.com/manual/reference/method/db.collection.distinct/)) allows us to review the unique (that is, *distinct*) values for a particular `field` retrieved from a specfied `query`.\n",
    "\n",
    "You might recall had a road category `PM`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_category_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-success"
    ]
   },
   "source": [
    "*In passing, you might notice that `rural` roads are identified by a a letter `R` in the second character position in the code, `urban` roads by the letter `U` in the same position, and motorways by the letter `M`. The first letter appears to identify the road class (principle, trunk, U, B or C.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's use that to satisfy our curiosity and see just what might be considered as a \"principal motorway\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roads_collection.distinct('Road', {'RCat': 'PM'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... All others are presumably *trunk motorways*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of road link lengths\n",
    "\n",
    "Reconsidering the road link lengths, one thing the average lengths shown so far don't tell us about the distribution of lengths of different road links, so let's explore that.\n",
    "\n",
    "#### Generating summary statistics\n",
    "\n",
    "If we pull back the lengths for every road link and category into a *pandas* dataframe, we can easily run some summary statistics over the data using the *pandas* dataframe `.describe()` method. Let's just grab the data into a simple dataframe directly from a simple query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_lengths_df = pd.DataFrame(roads_collection.find({}, {'CP':1, 'RCat':1, 'LenNet':1, '_id':0}))\n",
    "road_lengths_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then review the summary statistics of the data contained in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_lengths_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate similar statistics using an aggregation pipeline which avoids having to download a large number of results into memory within in potentially very long *pandas* dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = {'$group': {'_id': None,\n",
    "                    'length': {'$avg': '$LenNet'},\n",
    "                    'count': {'$sum': 1},\n",
    "                    'std': {'$stdDevPop': '$LenNet'},\n",
    "                    'min': {'$min': '$LenNet'}\n",
    "                   }}\n",
    "\n",
    "project = {'$project': {'length': '$length',\n",
    "                        'count': '$count',\n",
    "                        'std': '$std',\n",
    "                        'min': '$min',\n",
    "                        '_id':0}}\n",
    "\n",
    "pipeline = [group, project]\n",
    "\n",
    "list(roads_collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the long *pandas* dataframe containing the road segment length for each count point, we can use the  `.hist()` method to plot a histogram of the road length values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_lengths_df['LenNet'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *seaborn* `.distplot()` provides an alternative plot, optionally overlaying a continuous *kernel density estimate (kde)* model of the distribution on top of a histogram.\n",
    "\n",
    "*Pass `kde=True` into the plot to display an overplotted continuous model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.distplot(road_lengths_df['LenNet'],\n",
    "              # Specify the bin break points for binning the data\n",
    "              bins=[0, 6, 12, 16, 22, 35, 100],\n",
    "              kde=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning data using a `$bucket` pipeline stage\n",
    "\n",
    "We can also use an aggregation pipeline to \"bin\" or \"bucket\" counts into different road length ranges using an aggregation pipeline `$bucket` stage.\n",
    "\n",
    "For example, we might bin the road lengths into buckets of road lengths `[0, 6), [6, 12), [12, 16), [16, 22), [22, 35), [35, 100)`,  where the lower bound values are inclusive and the upper bound values are exclusive: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "bucket = {'$bucket':\n",
    "          {'groupBy': \"$LenNet\",\n",
    "           'boundaries': [0, 6, 12, 16, 22, 35, 100],\n",
    "           'output':\n",
    "               { \"count\": { '$sum': 1 } }\n",
    "          }\n",
    "         }\n",
    "\n",
    "list(roads_collection.aggregate([bucket]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then cast this to a dataframe and plot a bar chart from the result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-success"
    ]
   },
   "source": [
    "*It's not quite a histogram, but it gets the idea of the distribution across, just as long as you remember that the bars represent different size bins...!)*\n",
    "\n",
    "*Also note that the axes could be labeled a little more clearly. As it stands, this chart is probably okay as a sketch for helping you get a quick overview of the data, but it's not really appropriate as a publication ready chart.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(list(roads_collection.aggregate([bucket])))\n",
    "sns.barplot(x='_id', y='count', color='royalblue', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the data\n",
    "\n",
    "From the summary statistics and the visualisations, it seems the the majority of road links are very short, with a few that are longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "If you are working through this Notebook as part of an inline exercise, return to the module materials now.\n",
    "\n",
    "If you are working through this set of Notebooks as a whole, move on to notebook `15.6 Working with roads location data`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
