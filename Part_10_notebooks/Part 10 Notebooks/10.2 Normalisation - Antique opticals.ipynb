{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"top\"></a>Normalisation - Antique Opticals: 45 minutes to scan: most time taken in 10.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook will walk you through the process of normalisation, using the example of _Antique Opticals_ taken from Harrington. The example is based on normalising the order data shown in Harrington figure 3.2, but extended to show all the steps moving to third normal form (3NF). Briefly, the data represents a set of customer orders for DVDs. See the module material for more information on this case study.\n",
    "\n",
    "You should follow this notebook to understand the steps undertaken in normalisation, but you need not attempt to reimplement the steps there. Instead, **treat this notebook as a reference guide**. As you're working through and understanding this Notebook, you may also find it useful to refer to Harrington chapter 7 for the fine details of normalisation and normal forms. However, the key ideas behind the normal forms are repeated here.\n",
    "\n",
    "In Notebook 10.3, you will normalise the Prescription running example, following a similar process to here. While you work through Notebook 10.3, refer back to this notebook for how to address the tasks in normalisation.\n",
    "\n",
    "* [Moving to first normal form (1NF)](#1nf)\n",
    "* [Moving to second normal form (2NF)](#2nf)\n",
    "* [Moving to third normal form (3NF)](#3nf)\n",
    "* [Discussion](#discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next group of cells set up your database connection, and reset the database to a clean state. Check notebook *08.1 Data Definition Language in SQL* if you are unsure what the next cells do.\n",
    "\n",
    "You may need to change the given values of the variables `DB_USER` and `DB_PWD`, depending on which environment you are using"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If you are using the remote environment, change this cell\n",
    "# type to \"code\", and execute it\n",
    "\n",
    "DB_USER='xxx99'            # Enter your OUCU here (in quotes)\n",
    "DB_PWD='your_password'     # Enter your password here (in quotes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If you are using a locally hosted environment, change this cell\n",
    "# type to \"code\", and execute it\n",
    "\n",
    "DB_USER='tm351'\n",
    "DB_PWD='tm351'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the connection\n",
    "\n",
    "%run sql_init.ipynb\n",
    "print(\"Connecting with connection string : {}\".format(DB_CONNECTION))\n",
    "%sql $DB_CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run reset_databases.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"1nf\"></a> Moving from unnormalised data to first formal form (1NF)\n",
    "* [Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the mantra: to be in third normal form, \n",
    "\n",
    "> attributes must be dependent on the key, the whole key, and nothing but the key.\n",
    "\n",
    "This is our final destination, but first we need to move to first normal form (1NF). To be in 1NF, we have to ensure that the final clause of the mantra is true: each attribute must depend on nothing but the key. In other words, for one value of a given key in a relation, there must be exactly one value for each attribute. If there are multiple values for each key, it means the attribute value depends on more than just the key.\n",
    "\n",
    "Where there are multiple values of an attribute for a key, a _repeating group_, we need to extract the repeating values into a new relation.\n",
    "\n",
    "More formally, **a relation in 1NF has no repeating groups**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an implementation note, we'll be working initially with DataFrames before moving to PostgreSQL. The tables in SQL databases, like PostgreSQL, are based on relations which are, by definition, in first normal form (1NF). Therefore, SQL databases have difficulty representing truly unnormalised data where there can be more than one value for each attribute for a given key. We'll handle the unnormalised data in a DataFrame, then move the data into PostgresSQL once it's in 1NF. \n",
    "\n",
    "(Actually, most RDBMSs allow for non-primitive data in table cells, such as storing lists of numbers, but we'll not go into that here for simplicity of presentation.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading some sample data into a DataFrame and see where we are. We have created an initial CSV file containing some data for the Antique Opticals database in the file `antique-opticals.csv`, which we have included in this folder.\n",
    "\n",
    "As in notebook 10.1, we will use pandas' `.read_csv()` function to import the data from the CSV file into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_detail_df = pd.read_csv('antique-opticals.csv')\n",
    "orders_detail_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite wide, so let's look at the first few rows. We can use the `.T` method to transpose these rows and make the data a bit more readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 rows of orders_detail_df, transposed\n",
    "\n",
    "orders_detail_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our understanding of the domain suggests that there should be a `customer` relation with `customer_number` as the key, but the layout shows there are multiple values for some attributes for each `customer_number`. For example, we can see that Reed Calderon made two orders, on 29th July and 12th November, and there were two disks in each order. \n",
    "\n",
    "Hence, the `order_date` does not depend on just the `customer_number`. Nor does `title` depend on just the `customer_number`, and `title` does not depend on just the `order_number` either.\n",
    "\n",
    "That means this dataset is not in 1NF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to move to 1NF, we need to extract the repeating groups into separate relations.\n",
    "\n",
    "There are three 1NF relations here: \n",
    "1. `customer`, with one row for each `customer_number`,\n",
    "2. `order`, with one row for each `order_number`, and\n",
    "3. `order_item`, with several rows for each `order_number`.\n",
    "\n",
    "We'll work out the correct key for `order_item` when we've rearranged the data a bit and can see things more clearly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `customer` relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by pulling out the customer data into a new DataFrame. We can create a new DataFrame, `customers_df`, by pulling out the columns that we expect to appear in `customers_df`, which are `customer_number`, `first_name`, `surname`, `street`, `postcode` and `phone_number`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = orders_detail_df[\n",
    "    ['customer_number', 'first_name', 'surname', 'street', 'postcode', 'phone_number']\n",
    "]\n",
    "\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this is a bit messy, with duplication of rows where a customer created several orders. We can remove these repeated rows with the `.drop_duplicates()` method. Note that as used here, `.drop_duplicates()` returns a new dataframe, rather than making the update in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the drop_duplicates method to remove repeated columns\n",
    "\n",
    "customers_df=customers_df.drop_duplicates()\n",
    "customers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you learned in Part 8, each relation needs to have a *primary key*, which is unique for each row in the relation. pandas' Series have an attribute `.is_unique`, which is True if all the members of the series are different, and False otherwise.\n",
    "\n",
    "We can use this attribute to determine which columns are candidate keys for the relation (remember from [Part 8, section 4](https://learn2.open.ac.uk/mod/oucontent/olinkremote.php?website=TM351&targetdoc=Part%208%20Introduction%20to%20relational%20databases&targetptr=4) that a candidate key is \"a column (or combination of columns) which uniquely identifies each row\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in customers_df.columns:\n",
    "    print(c + ' : ' + str(customers_df[c].is_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns `customer_number`, `street`, `postcode` and `phone_number` all contain unique values, so any of these columns could form the primary key.\n",
    "\n",
    "In fact, `customer_number` looks as though it will do the job, which is what we were expecting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `orders` relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll extract the `orders` relation in the same way as above: pull out the columns, and drop the duplicates.\n",
    "\n",
    "First, we'll pull out the columns. For the `orders` relation, the columns we want are `order_number`, `customer_number` and `order_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the appropriate columns from orders_detail\n",
    "\n",
    "orders_df = orders_detail_df[['order_number', 'customer_number', 'order_date']]\n",
    "\n",
    "# and remove any duplicated rows:\n",
    "\n",
    "orders_df=orders_df.drop_duplicates()\n",
    "orders_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could the primary key be for `orders`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in orders_df.columns:\n",
    "    print(c + ' : ' + str(orders_df[c].is_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`order_number` seems like a good candidate key for this relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `order_items` relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to extract the `order_items` relation. As before, specify the columns, and then drop the duplicated rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the appropriate columns from orders_detail_df\n",
    "order_items_df = orders_detail_df[\n",
    "    ['order_number', 'item_number', 'title', 'price', 'item_dispatched', 'distributor_id', 'distributor']]\n",
    "\n",
    "# and remove any duplicated rows:\n",
    "order_items_df=order_items_df.drop_duplicates()\n",
    "\n",
    "order_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what should we use as a primary key for `order_items`? Again, let's look for columns which do not contain any duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in order_items_df.columns:\n",
    "    print(c + ' : ' + str(order_items_df[c].is_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, no single column is a candidate key, implying that we need a combination of columns to make a composite key. Let's try `(order_number, item_number)` (note how we convert both series to strings using the `.astype(str)` method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(order_items_df['order_number'].astype(str) + order_items_df['item_number'].astype(str)).is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.is_unique` attribute is now True. The combination of `order_number` and `item_number` contains no duplicates, and is therefore a candidate key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreating the original table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have three dataframes representing relations in 1NF: `customers_df`, `orders_df`, and `order_items_df`. Let's make sure we can combine them to recreate the original table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([`merge`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) is covered in notebook *3.3 Combining data from multiple datasets*; the syntax is \n",
    "\n",
    "<code>this_dataframe.merge(that_dataframe, on=['column_1', 'column_2', ...])</code>\n",
    "\n",
    "This does an inner join on `this_dataframe` and `that_dataframe`, using the columns specified. The columns must be present in both DataFrames for this to work. Should you wish to use some kind of outer join, use the `how` keyword argument.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recombined_customers_df=customers_df.merge(orders_df, on=['customer_number']).merge(order_items_df, on=['order_number'])\n",
    "\n",
    "recombined_customers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks OK, but are all the values the same? We want to compare with the original dataframe, `orders_detail_df`. For this, we can use the `.equals()` method on a dataframe. However, there's a small gotcha: the columns need to be in the same order in both dataframes. Therefore, we need to reorder the columns when we call `.equals()`. In the next cell, the expression\n",
    "\n",
    "<code>recombined_customers_df[orders_detail_df.columns]</code>\n",
    "\n",
    "returns the dataframe `recombined_customers_df`, but with the columns in the same order as the columns in `orders_detail_df`. This allows us to do the equality test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_detail_df.equals(recombined_customers_df[orders_detail_df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equality check should have returned True, showing that the dataframes `customers_df`, `orders_df` and `order_items_df` can be reconstructed into the dataframe `orders_detail_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the 1NF relations into PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have three 1NF relations, let's put them in PostreSQL for the subsequent steps.\n",
    "\n",
    "Note that we have to call the `order` table `disk_order`, as `ORDER` itself is an SQL reserved word.\n",
    "\n",
    "For each of the dataframes, we will create a table in PostgreSQL, and add the primary key that we have identified, and appopriate foreign keys. Check Notebook *09.1: Defining Foreign Keys in SQL* if you need to remind yourself how foreign keys are defined in SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create the `customer` table from the `customers_df` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.to_sql('customer',\n",
    "                    DB_CONNECTION,\n",
    "                    if_exists='replace',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add the primary key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE customer \n",
    "ADD CONSTRAINT customer_pk\n",
    "    PRIMARY KEY (customer_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the `disk_order` table from the `orders_df` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.to_sql('disk_order',\n",
    "                 DB_CONNECTION,\n",
    "                 if_exists='replace',\n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add the primary key and a foreign key referencing the `customer` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE disk_order\n",
    "ADD CONSTRAINT disk_order_pk\n",
    "    PRIMARY KEY (order_number);\n",
    "\n",
    "ALTER TABLE disk_order\n",
    "ADD CONSTRAINT disk_order_customer_fk \n",
    "    FOREIGN KEY (customer_number) REFERENCES customer;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create the `order_item` table from the `order_items_df` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items_df.to_sql('order_item',\n",
    "                      DB_CONNECTION,\n",
    "                      if_exists='replace',\n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add the composite primary key and a foreign key referencing the `disk_order` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE order_item \n",
    "ADD CONSTRAINT order_item_pk\n",
    "    PRIMARY KEY (order_number, item_number);\n",
    "\n",
    "ALTER TABLE order_item\n",
    "ADD CONSTRAINT order_item_disk_order_fk \n",
    "    FOREIGN KEY (order_number) REFERENCES disk_order;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the PostgreSQL tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we can extract the data from the database tables. Start with a simple queries on each of the `customer`, `disk_order` and `order_item` tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT *\n",
    "FROM customer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * \n",
    "FROM disk_order;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT *\n",
    "FROM order_item;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make sure we can recreate the original dataset from the PostgreSQL tables.\n",
    "\n",
    "(Convenience: get Jupyter to print the column names in a form we can cut-and-paste into the SQL query.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(orders_detail_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we're using the `<<` notation of SQL Magic to put the results of the query into a Python variable. We've also told SQL magic to convert SQL result sets into pandas DataFrames for us. (See the section *Executing SQL queries* in  Notebook *08.1 Data Definition Language in SQL.ipynb* to see the use of the `<<` notation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sql orders_detail_recreated <<\n",
    "\n",
    "SELECT customer.customer_number, first_name, surname, street, postcode, phone_number, \n",
    "    disk_order.order_number, order_date, item_number, title, price, item_dispatched, \n",
    "    distributor_id, distributor\n",
    "FROM customer, disk_order, order_item\n",
    "WHERE customer.customer_number = disk_order.customer_number\n",
    "    AND disk_order.order_number = order_item.order_number\n",
    "ORDER BY customer_number, order_number, item_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_detail_recreated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, check that the recreated dataset is the same as the one we started with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orders_detail_df.equals(orders_detail_recreated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 1\n",
    "Draw the ERD of these three relations: `customer`, `disk_order`, and `order_item`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "<img src=\"images/antique-opticals-1nf.png\" alt=\"Antique Opticals 1NF ERD\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "The participation conditions depend on the specifics of the domain. It seems reasonable that every order item is part of an order. It seems reasonable (though not necessarily so) that every order contains at least one item. It seems reasonable that every order relates to a customer, but that not every customer must have an order. However, in a real situation, you'd need to check these assumptions with what the actual business rules are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### End of Activity 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"2nf\"></a>Moving to second normal form (2NF)\n",
    "* [Top](#top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reiterate, to be in third normal form, \n",
    "> attributes must be dependent on the key, the whole key, and nothing but the key.\n",
    "\n",
    "We have relations in 1NF. To move to second normal form (2NF), we have to ensure the second clause of that mantra: each attribute depends on all elements of a composite primary key (while all relations remain in 1NF). \n",
    "\n",
    "\"Depends\" in this context means _functionally dependent_: attribute *a* depends on attribute *b* if, when we know the value of *b*, there is precisely one value of *a*. Which functional dependencies hold for a given dataset depend on the real-world context and is not something which can be gleaned from the data alone.\n",
    "\n",
    "For example, For _Antique Opticals_, `surname` is functionally dependent on `customer_number`: if we know the `customer_number`, we know the `surname`. The reverse is not true: if we know the `surname`, we don't necessarily know the `customer_number` (consider the `surname` \"Blankley\" in the _Antique Opticals_ example). \n",
    "\n",
    "Formally, **a relation in 2NF has all attributes functionally dependent on the whole of the primary key**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The functional dependencies in this example are:\n",
    "\n",
    "| This attribute | functionally defines this attribute |\n",
    "| ------------- |:------------- |\n",
    "| `customer_number` | `first_name` |\n",
    "| `customer_number` | `surname` |\n",
    "| `customer_number` | `street` |\n",
    "| `customer_number` | `postcode` |\n",
    "| `customer_number` | `phone_number` |\n",
    "| `order_number` | `order_date` |\n",
    "| `order_number` | `customer_number` |\n",
    "| `item_number` | `title` |\n",
    "| `item_number` | `price` |\n",
    "| `item_number` | `distributor_id`|\n",
    "| (`order_number`, `item_number`) | `item_dispatched` |\n",
    "| `distributor_id` | `distributor` |\n",
    "\n",
    "In moving to 2NF, we extract the attributes which are dependent on part of the primary key into new relations, such that in each relation, the attributes are dependent on all parts of the key.\n",
    "\n",
    "We only need consider relations with composite primary keys; relations with simple primary keys are automatically in 2NF.\n",
    "\n",
    "In the _Antique Opticals_ example, there is only one relation (table) with a composite key: `order_item`, with key `(order_number, item_number)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT *\n",
    "FROM order_item;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this relation, most attributes describe the item, not the particular state of the ordered item. The functional dependencies tell us that the `title`, `price`, `distributor_id` and `distributor` depend on the `item_number` alone. `item_dispatched` depends on the combination of `order_number` and `item_number`. No attributes in this relation depend on the `order_number` alone.\n",
    "\n",
    "That means we should split `order_item` into two relations: one with the existing composite primary key holding just the `item_dispatched` attribute, with all other attributes moving to an `item` relation.\n",
    "\n",
    "First, let's check that there's only one value of `title`, `price`, `distributor_id` and `distributor` for each `item_number`. The `DISTINCT` keyword means we only count how many _different_ values there are. The `GROUP BY` means we calculate the counts for each `item_number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT item_number, COUNT(DISTINCT title) AS n_title,  COUNT(DISTINCT price) AS n_price,  \n",
    "    COUNT(DISTINCT distributor_id) AS n_dist_id,  COUNT(DISTINCT distributor) AS n_dist\n",
    "FROM order_item\n",
    "GROUP BY item_number;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, but if there were many items, we shouldn't be reliant on someone scanning down the list. Let's ask the database for items where there's more than one description per code (using `HAVING` to filter the groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT item_number\n",
    "FROM order_item\n",
    "GROUP BY item_number\n",
    "HAVING COUNT(DISTINCT title) > 1 OR COUNT(DISTINCT price) > 1 OR  \n",
    "    COUNT(DISTINCT distributor_id) > 1 OR COUNT(DISTINCT distributor) > 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All seems fine, so now let's create the two new tables.\n",
    "\n",
    "Note the `CREATE TABLE ... AS SELECT ...` notation. As we saw in notebook *08.2 Data Manipulation Language in SQL*, this creates a new table and immediately populates it. The column names come from how they appear in the result of the `SELECT`; the column types come from the source table; and the values inserted into the new table come from the results of the query. We use `DISTINCT` to prevent taking multiple rows where an item has been ordered more than once.\n",
    "\n",
    "We also create the primary key on this table, and quickly check that it looks sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "DROP TABLE IF EXISTS distributor_item CASCADE;\n",
    "\n",
    "CREATE TABLE distributor_item AS\n",
    "    SELECT DISTINCT item_number, title, price, distributor_id, distributor\n",
    "    FROM order_item;\n",
    "    \n",
    "ALTER TABLE distributor_item\n",
    "ADD CONSTRAINT distributor_item_pk\n",
    "    PRIMARY KEY (item_number);\n",
    "\n",
    "SELECT * \n",
    "FROM distributor_item;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the `order_line` table in much the same way. We also create the primary key constraint and the two foreign key constraints, connecting `order_line` to `disk_order` and `distributor_item`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS order_line;\n",
    "\n",
    "CREATE TABLE order_line AS\n",
    "    SELECT DISTINCT order_number, item_number, item_dispatched\n",
    "    FROM order_item;\n",
    "    \n",
    "ALTER TABLE order_line \n",
    "ADD CONSTRAINT order_line_pk\n",
    "    PRIMARY KEY (order_number, item_number);\n",
    "\n",
    "ALTER TABLE order_line \n",
    "ADD CONSTRAINT order_line_distributor_item_fk \n",
    "    FOREIGN KEY (item_number) REFERENCES distributor_item;\n",
    "\n",
    "ALTER TABLE order_line\n",
    "ADD CONSTRAINT order_line_disk_order_fk \n",
    "    FOREIGN KEY (order_number) REFERENCES disk_order (order_number);\n",
    "    \n",
    "SELECT * \n",
    "FROM order_line;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check we can recreate the `order_item` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql recreated_order_items << \n",
    "\n",
    "SELECT order_line.order_number, order_line.item_number, title, price, item_dispatched, \n",
    "    distributor_id, distributor \n",
    "FROM order_line, distributor_item\n",
    "WHERE order_line.item_number = distributor_item.item_number\n",
    "ORDER BY order_number, item_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreated_order_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems OK, but let's check formally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql order_items << \n",
    "\n",
    "SELECT order_number, item_number, title, price, item_dispatched, \n",
    "    distributor_id, distributor \n",
    "FROM order_item\n",
    "ORDER BY order_number, item_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(recreated_order_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the result sets using the `.equals()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items.equals(recreated_order_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "Finally, let's get rid of that `order_item` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE order_item;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "Draw an ERD of the relations `customer`, `disk_order`, `order_line`, and `distributor_item`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "<img src=\"images/antique-opticals-2nf.png\" alt=\"Antique Opticals 2NF ERD\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "Again, the participation conditions depend on the domain. While every order line must be for some item, it's not clear if _Antique Opticals_ can hold items without an order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### End of Activity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"3nf\"></a>Moving to Third Normal Form (3NF)\n",
    "* [Top](#top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To be in third normal form, \n",
    "> attributes must be dependent on the key, the whole key, and nothing but the key.\n",
    "\n",
    "To move to third normal form (3NF), we have to ensure the first clause of that mantra: each attribute is directly functionally dependent on the key, and not functionally dependent on any other attribute. As before, we ensure this is true by splitting relations as necessary, while ensuring that all relations remain in 2NF (and hence also in 1NF). \n",
    "\n",
    "Formally, **a relation in 3NF has all attributes _directly_ functionally dependent on the whole of the primary key**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To reiterate, the functional dependencies in a dataset are defined by the real-world context. Just to reiterate, the functional dependencies in this example are:\n",
    "\n",
    "| This attribute | functionally defines this attribute |\n",
    "| ------------- |:------------- |\n",
    "| `customer_number` | `first_name` |\n",
    "| `customer_number` | `surname` |\n",
    "| `customer_number` | `street` |\n",
    "| `customer_number` | `postcode` |\n",
    "| `customer_number` | `phone_number` |\n",
    "| `order_number` | `order_date` |\n",
    "| `order_number` | `customer_number` |\n",
    "| `item_number` | `title` |\n",
    "| `item_number` | `price` |\n",
    "| `item_number` | `distributor_id`|\n",
    "| (`order_number`, `item_number`) | `item_dispatched` |\n",
    "| `distributor_id` | `distributor` |\n",
    "\n",
    "In the _Antique Opticals_ domain, all attributes are directly dependent on their respective primary keys apart from the `distributor`. This is directly dependent on the `distributor_id` attribute, not the `item_number`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the new `item` and `distributor` tables, pulling data from the `distributor_item` table.\n",
    "\n",
    "First, the `distributor`. Check that there is only one `distributor` for each `distributor_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT distributor_id\n",
    "FROM distributor_item\n",
    "GROUP BY distributor_id\n",
    "HAVING COUNT(DISTINCT distributor) > 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's fine, so create the `distributor` table and add its primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS distributor CASCADE;\n",
    "\n",
    "CREATE TABLE distributor AS\n",
    "    SELECT DISTINCT distributor_id, distributor\n",
    "    FROM distributor_item;\n",
    "    \n",
    "ALTER TABLE distributor\n",
    "ADD CONSTRAINT distributor_pk\n",
    " PRIMARY KEY (distributor_id);\n",
    "\n",
    "SELECT *\n",
    "FROM distributor;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `item`. No need to check for uniqueness as we already have `item_number` as the primary key in `distributor_item`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS item CASCADE;\n",
    "\n",
    "CREATE TABLE item AS\n",
    "    SELECT DISTINCT item_number, title, price, distributor_id\n",
    "    FROM distributor_item;\n",
    "    \n",
    "ALTER TABLE item\n",
    "ADD CONSTRAINT item_pk\n",
    "    PRIMARY KEY (item_number);\n",
    "\n",
    "ALTER TABLE item\n",
    "ADD CONSTRAINT item_distributor_fk \n",
    "    FOREIGN KEY (distributor_id) REFERENCES distributor;\n",
    "\n",
    "SELECT *\n",
    "FROM item;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add the foreign key constraint from `order_line` to `item`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE order_line\n",
    "ADD CONSTRAINT order_line_item_fk \n",
    "    FOREIGN KEY (item_number) REFERENCES item;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we recreate the `distributor_item` table from the normalised tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql recreated_distributor_items <<\n",
    "\n",
    "SELECT item_number, title, price, item.distributor_id, distributor\n",
    "FROM item, distributor\n",
    "WHERE distributor.distributor_id = item.distributor_id\n",
    "ORDER BY item_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreated_distributor_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, but again, let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql distributor_items <<\n",
    "\n",
    "SELECT item_number, title, price, distributor_id, distributor\n",
    "FROM distributor_item\n",
    "ORDER BY item_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributor_items.equals(recreated_distributor_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, can we recreate the original dataset from the normalised tables?\n",
    "\n",
    "As we're joining five tables, the SQL query is rather long, but not complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sql order_details_recreated << \n",
    "\n",
    "SELECT customer.customer_number, first_name, surname, street, postcode, phone_number, \n",
    "    disk_order.order_number, order_date, item.item_number, title, price, item_dispatched, \n",
    "    distributor.distributor_id, distributor\n",
    "FROM customer, disk_order, order_line, item, distributor\n",
    "WHERE customer.customer_number = disk_order.customer_number\n",
    "    AND disk_order.order_number = order_line.order_number\n",
    "    AND item.item_number = order_line.item_number\n",
    "    AND distributor.distributor_id = item.distributor_id\n",
    "ORDER BY customer.customer_number, disk_order.order_number, order_line.item_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_details_recreated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_detail_df.equals(order_details_recreated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Let's now get rid of the `distributor_item` table. Note that first we have to drop the foreign key constraint from `order_line` to `distributor_item`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE order_line\n",
    "DROP CONSTRAINT order_line_distributor_item_fk;\n",
    "\n",
    "DROP TABLE distributor_item;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "Draw an ERD of the relations `customer`, `disk_order`, `order_line`, `distributor`, and `item`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "<img src=\"images/antique-opticals-3nf.png\" alt=\"Antique Opticals 3NF ERD\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "Again, the participation conditions depending on the domain. It could well be that we can have items without a known distributor, and distributors who are not the source of any items. On the other hand, these relationships could be mandatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### End of Activity 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the normalisation worked example. We've seen how to decompose a large table into a set of normalised relations, and shown that those relations can be recombined to recover the original table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"discussion\"></a>Discussion\n",
    "* [Top](#top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are choices to be made at all steps in normalisation. In particular, we have choices to make about where to start. \n",
    "\n",
    "In this example, we started with the `customer_number` key, thinking that the `orders` relation would have multiple values for each `customer_number`. That moved us to splitting the original dataset into three relations in 1NF, and hence the rest of the steps above.\n",
    "\n",
    "The example in figure 3.2 of Harrington would lead us to start with data with `order_number` as the primary key. That wouldn't have customer details as repeating groups with orders.\n",
    "\n",
    "Alternatively, we could have started with rows indexed by `(order_number, item_number)`? That relation would be in 1NF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "If we'd started with either the `order_and_customer` (i.e. one row per order) or `ordered_item_and_order_and_customer` (i.e. one row per ordered item) relations, would we have ended with the same set of relations after moving to 3NF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "student": true
   },
   "source": [
    "Write your answer in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "Depending on where we started, the move to 1NF would be easier. In the most extreme example, starting with rows indexed by `(order_number, item_number)`, the move to 1NF would be trivial. If we started with `order_and_customer`, the move to 1NF would have generated the same `order_item` relation as we did in the main notebook. In both cases, the move to 2NF would again pull out the `distributor_item` relation. \n",
    "\n",
    "The move to 3NF would be much more involved, as there are many transitive functional dependencies in the original dataset. It would be at this step that the `customer`, `order`, and `distributor` relations would have been identified, based on the attributes which functionally depend on those relations' primary keys. For instance, the `order_and_customer` relation would have attributes like `surname` and `postcode` functionally dependent on the `customer_number`, not the `order_number`. That would have prompted us to split out the `customer`s from the `order`s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### End of Activity 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the process you've covered here outlines all the steps of normalisation, we've made some assumptions about the requirements of any OLTP (OnLine Transaction Processing: see Part 8, section 2) system using this data, assumptions that would not be valid in a live system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### Activity 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "Consider the `price` attribute.\n",
    "\n",
    "Why would treating the `price` as we have not be conscionable in a live system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "**Hint:** Consider an order for \"Batman Returns\" made now versus an order for \"Batman Returns\" made a year ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "student": true
   },
   "source": [
    "Write your answer in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### Our solution\n",
    "\n",
    "To reveal our solution, run this cell or click on the triangle symbol on the left-hand side of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "The price could well have changed over past year. If so, what would happen if a customer phoned up today, querying an order made last year? Perhaps more importantly, how much income should we declare to the tax service over the whole year?\n",
    "\n",
    "We need to distinguish between the price we would charge for an order placed now, and the price we actually charged a customer on an order. How we implement that depends on many factors. We could just store the price charged in the order line, copied from the current price when the order is placed. We could maintain a list of prices, annotated with the dates they're effective, and look up the charged price by using a combination of item number and order date. As with many things in computing, there's a trade-off between processing time and storage space used.\n",
    "\n",
    "A similar situation occurs with customer addresses, customer names, perhaps DVD titles, and many other things. The different ways of dealing with these issues is outside the scope of this module, but you should be aware of the issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "#### End of Activity 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook, you've followed the process of normalisation from unnormalised data to data in 3NF. You did this by splitting relations into new relations to ensure the new relations are in the required normal form. \n",
    "\n",
    "The formal details of the process are in the Hannington book, but remember the mnemonic: to be in third normal form, \n",
    "> attributes must be dependent on the key, the whole key, and nothing but the key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What next?\n",
    "If you are working through this Notebook as part of an inline exercise, return to the module materials now.\n",
    "\n",
    "If you are working through this set of Notebooks as a whole, move on to notebook *10.3 Normalisation - the Hospital scenario*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
